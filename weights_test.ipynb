{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# /nfsdata/laip/results/valid/Llama-3___1-Tulu-3-8B_logits.json\n",
    "# /nfsdata/laip/results/valid/Mistral-7B-Instruct-v0___3_logits.json\n",
    "# /nfsdata/laip/results/valid/Meta-Llama-3___1-8B-Instruct_logits.json\n",
    "# /nfsdata/laip/results/valid/internlm3-8b-instruct_logits.json\n",
    "\n",
    "# /home/laip/InternalScore/results/valid/Llama-3___1-Tulu-3-8B_with_feedback_logits.json\n",
    "# /home/laip/InternalScore/results/valid/Mistral-7B-Instruct-v0___3_with_feedback_logits.json\n",
    "# /home/laip/InternalScore/results/valid/Meta-Llama-3___1-8B-Instruct_with_feedback_logits.json\n",
    "# /home/laip/InternalScore/results/valid/internlm3-8b-instruct_with_feedback_logits.json\n",
    "\n",
    "\n",
    "data_path = '/nfsdata/laip/results/valid/Meta-Llama-3___1-8B-Instruct_logits.json'\n",
    "data = json.load(open(data_path))\n",
    "# with open(data_path) as f:\n",
    "#     data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch.nn as nn\n",
    "\n",
    "def optimize_layer_weights(logits_list, targets, loss_fn, num_epochs=2, lr=0.01,min_lr = 1e-3):\n",
    "    all_res=  []\n",
    "    L = len(logits_list[0])  \n",
    "    \n",
    "    # 初始化权重\n",
    "    weights = torch.nn.Parameter(torch.ones(L, requires_grad=True))\n",
    "    # weights = torch.zeros(L)\n",
    "    # weights[-1] = 1\n",
    "    # weights = torch.nn.Parameter(weights,requires_grad=True)\n",
    "\n",
    "    optimizer = optim.Adam([weights], lr=lr)\n",
    "    #scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=min_lr)\n",
    "\n",
    "    for epoch in trange(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for sample_idx in trange(len(logits_list)):  # 遍历所有样本\n",
    "            logits = logits_list[sample_idx]  \n",
    "            target = targets[sample_idx]  \n",
    "\n",
    "            if type(loss_fn) == torch.nn.modules.loss.CrossEntropyLoss:\n",
    "                target = target - 1\n",
    "                target = torch.tensor(target,dtype=torch.long)\n",
    "\n",
    "            normalized_weights = torch.softmax(weights, dim=0)\n",
    "\n",
    "            # 计算加权和\n",
    "            weighted_sum = torch.zeros_like(logits[0])  \n",
    "            for l in range(L):\n",
    "                if type(loss_fn) == torch.nn.modules.loss.CrossEntropyLoss:\n",
    "                    weighted_sum += normalized_weights[l] * logits[l]  # logits累积加权\n",
    "                    predictions = weighted_sum\n",
    "                else:\n",
    "                    weighted_sum += normalized_weights[l] * (torch.tensor(logits[l])*torch.tensor([1,2,3,4,5])).sum()  # 加权求和\n",
    "                    predictions = weighted_sum  # 预测结果\n",
    "\n",
    "\n",
    "            loss = loss_fn(predictions,target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_res.append(total_loss/(sample_idx+1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "        # 每个 epoch 打印损失\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return torch.softmax(weights, dim=0).detach(),all_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import json\n",
    "# from tqdm import tqdm,trange\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "# all_loss = []\n",
    "# def optimize_layer_weights(logits_list, targets, loss_fn1,loss_fn2, num_epochs=4, lr=0.01 , add_loss = True):\n",
    "\n",
    "#     L = len(logits_list[0])  \n",
    "\n",
    "#     # 初始化权重\n",
    "#     weights = torch.nn.Parameter(torch.randn(L, requires_grad=True))\n",
    "#     beta = torch.nn.Parameter(torch.tensor(1, requires_grad=True,dtype=torch.float32))\n",
    "#     alpha = torch.nn.Parameter(torch.tensor(0, requires_grad=True,dtype=torch.float32))\n",
    "#     bias = torch.nn.Parameter(torch.tensor(0, requires_grad=True,dtype=torch.float32))\n",
    "#     # weights = torch.zeros(L)\n",
    "#     # weights[-1] = 1\n",
    "#     # weights = torch.nn.Parameter(weights,requires_grad=True)\n",
    "\n",
    "#     optimizer = optim.Adam([weights,beta,alpha,bias], lr=lr)\n",
    "\n",
    "#     for epoch in trange(num_epochs):\n",
    "#         total_loss = 0\n",
    "\n",
    "#         for sample_idx in trange(len(logits_list)):  # 遍历所有样本\n",
    "#             logits = logits_list[sample_idx]  \n",
    "#             target = targets[sample_idx]  \n",
    "\n",
    "#             target1 = target - 1\n",
    "#             target1 = torch.tensor(target1,dtype=torch.long)\n",
    "#             target2 = target\n",
    "\n",
    "#             normalized_weights = torch.softmax(weights, dim=0)\n",
    "\n",
    "#             # 计算加权和\n",
    "#             weighted_sum1 = torch.zeros_like(logits[0])  \n",
    "#             weighted_sum2 = torch.tensor(0,dtype = torch.float32)\n",
    "\n",
    "#             for l in range(L):\n",
    "                \n",
    "#                 weighted_sum1 += normalized_weights[l] * logits[l]  # logits累积加权\n",
    "#                 weighted_sum2 += (normalized_weights[l] * (torch.tensor(logits[l]).softmax(dim=-1)*torch.tensor([1,2,3,4,5])).sum()).sum()  # 加权求和\n",
    "                \n",
    "#             predictions1 = weighted_sum1\n",
    "#             predictions2 = beta*weighted_sum2.sum()+bias  # 预测结果\n",
    "\n",
    "#             alpha_norm = torch.sigmoid(alpha)\n",
    "#             loss = loss_fn1(predictions1,target1) +alpha_norm*loss_fn2(predictions2,target2)\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "#             all_loss.append(total_loss/(sample_idx+1))\n",
    "\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         avg_loss = total_loss / len(logits_list)\n",
    "#         # 每个 epoch 打印损失\n",
    "#         print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#     return torch.softmax(weights, dim=0).detach(),beta.detach(),bias.detach(),all_loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "def optimize_layer_weights(\n",
    "    logits_list,\n",
    "    targets,\n",
    "    loss_fn1,\n",
    "    loss_fn2,\n",
    "    num_epochs=4,\n",
    "    batch_size=32,\n",
    "    lr=0.02,\n",
    "    min_lr=1e-4,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"带余弦退火学习率调度和批量训练的优化版本\"\"\"\n",
    "    # 数据预处理 -------------------------------------------------\n",
    "    # 转换为张量并确保设备一致性\n",
    "    L = len(logits_list[0])\n",
    "    num_classes = len(logits_list[0][0])\n",
    "    \n",
    "    # 将输入数据转换为张量 [num_samples, L, num_classes]\n",
    "    logits_tensor = torch.tensor(logits_list,device=device)\n",
    "    targets = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "    \n",
    "    # 转换目标张量\n",
    "    \n",
    "    targets_reg = torch.tensor(targets, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # 系数张量\n",
    "    coefficients = torch.tensor([1.,2.,3.,4.,5.], device=device)\n",
    "    \n",
    "    # 参数初始化 -------------------------------------------------\n",
    "    weights = nn.Parameter(torch.ones(L, device=device))\n",
    "    beta = nn.Parameter(torch.tensor(1.0, device=device))\n",
    "    alpha = nn.Parameter(torch.tensor(1.0, device=device))\n",
    "    bias = nn.Parameter(torch.tensor(0.5, device=device))\n",
    "    \n",
    "    # 优化器和调度器 ---------------------------------------------\n",
    "    #optimizer = optim.Adam([weights, beta, alpha, bias], lr=lr)\n",
    "    optimizer = optim.Adam([weights], lr=lr)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=min_lr)\n",
    "    \n",
    "    # 训练循环 ---------------------------------------------------\n",
    "    all_losses = []\n",
    "    num_samples = len(logits_list)\n",
    "    \n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        # 随机打乱数据\n",
    "        indices = torch.randperm(num_samples)\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            # 获取当前batch\n",
    "            batch_indices = indices[batch_start : batch_start+batch_size]\n",
    "            batch_logits = logits_tensor[batch_indices]  # [B, L, C]\n",
    "            batch_cls_targets = targets[batch_indices]-1\n",
    "            batch_reg_targets = targets_reg[batch_indices]\n",
    "            \n",
    "            # 前向传播 -------------------------------------------\n",
    "            normalized_weights = torch.softmax(weights, dim=0)\n",
    "            \n",
    "            # 分类预测 [B, C]\n",
    "            cls_pred = torch.einsum('l,blc->bc', normalized_weights, batch_logits)\n",
    "            \n",
    "            # 回归预测计算\n",
    "            # 1. 计算每个样本每层的得分 [B, L]\n",
    "            layer_scores = torch.softmax(batch_logits, dim=-1) @ coefficients\n",
    "            # 2. 加权求和 [B]\n",
    "            reg_pred = beta * (layer_scores @ normalized_weights) + bias\n",
    "            \n",
    "            # 损失计算 -------------------------------------------\n",
    "            alpha_norm = torch.sigmoid(alpha)\n",
    "            loss_cls = loss_fn1(cls_pred, batch_cls_targets)\n",
    "            loss_reg = loss_fn2(reg_pred, batch_reg_targets)\n",
    "            #total_loss = alpha_norm * loss_cls + (1 - alpha_norm) * loss_reg\n",
    "            total_loss = loss_cls\n",
    "            \n",
    "            # 反向传播 -------------------------------------------\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 记录损失\n",
    "            all_losses.append(total_loss.item())\n",
    "            epoch_loss += total_loss.item()\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 打印统计信息\n",
    "        avg_loss = epoch_loss / (num_samples // batch_size + 1)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f} | LR: {current_lr:.2e}\")\n",
    "\n",
    "    return (\n",
    "        torch.softmax(weights, dim=0).detach(),\n",
    "        beta.detach(),\n",
    "        bias.detach(),\n",
    "        all_losses\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_score_ls = []\n",
    "logits_ls = []\n",
    "human_score_ls1 = []\n",
    "\n",
    "weighted_score_ls = []\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.MSELoss()\n",
    "\n",
    "for data1 in data:\n",
    "    df = pd.DataFrame(data1['df'])\n",
    "    if data1['weighted_socre']==-1:\n",
    "        continue\n",
    "    _logits = torch.tensor([i for i in df['logits']],dtype=torch.float32)\n",
    "    #_logits = [i for i in df['logits']]\n",
    "    human_score_ls1.append(data1['human_score'])\n",
    "    if type(loss_fn) == torch.nn.modules.loss.CrossEntropyLoss:\n",
    "        human_score = torch.tensor(data1['human_score'],dtype=torch.long)\n",
    "        \n",
    "    else:\n",
    "        human_score = torch.tensor(data1['human_score'],dtype=torch.float32)\n",
    "\n",
    "    weighted_score = torch.tensor(df['weighted_score'].to_list(),dtype=torch.float32)\n",
    "    human_score_ls.append(human_score)\n",
    "    logits_ls.append(_logits)\n",
    "    weighted_score_ls.append(weighted_score)\n",
    "# for data1 in data:\n",
    "#     df = pd.DataFrame(data1['res'])\n",
    "#     if data1['pred_score']['weighted_socre']==-1:\n",
    "#         continue\n",
    "#     _logits = torch.tensor([i for i in df['logits']],dtype=torch.float32)\n",
    "\n",
    "#     if type(loss_fn) == torch.nn.modules.loss.CrossEntropyLoss:\n",
    "#         human_score = torch.tensor(int(data1['human']),dtype=torch.long)\n",
    "#     else:\n",
    "#         human_score = torch.tensor(int(data1['human']),dtype=torch.float32)\n",
    "\n",
    "#     weighted_score = torch.tensor(df['weighted_score'].to_list(),dtype=torch.float32)\n",
    "#     human_score_ls.append(human_score)\n",
    "#     logits_ls.append(_logits)\n",
    "#     weighted_score_ls.append(weighted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/tmp/ipykernel_992765/2492990320.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target,dtype=torch.long)\n",
      "100%|██████████| 990/990 [00:01<00:00, 592.86it/s]\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1511.6334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:01<00:00, 904.47it/s]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Loss: 1484.7884\n",
      "学习到的权重： tensor([0.0034, 0.0035, 0.0034, 0.0034, 0.0032, 0.0030, 0.0027, 0.0031, 0.0031,\n",
      "        0.0032, 0.0035, 0.0036, 0.0039, 0.0042, 0.0036, 0.0035, 0.0036, 0.0030,\n",
      "        0.0028, 0.0024, 0.0024, 0.0024, 0.0037, 0.8594, 0.0032, 0.0035, 0.0036,\n",
      "        0.0094, 0.0060, 0.0052, 0.0053, 0.0053, 0.0245])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f28118a10>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "# weights,beta,bias,all_loss = optimize_layer_weights(\n",
    "#                                         logits_ls, \n",
    "#                                         torch.tensor(human_score_ls1), \n",
    "#                                         loss_fn1 = nn.CrossEntropyLoss(),\n",
    "#                                         loss_fn2=nn.MSELoss(),\n",
    "#                                         num_epochs=10, \n",
    "#                                         batch_size = 128,\n",
    "#                                         lr=0.0001,\n",
    "#                                         min_lr=1e-4,\n",
    "#                                         )\n",
    "weights,all_loss = optimize_layer_weights(logits_ls, human_score_ls, loss_fn = nn.CrossEntropyLoss(),num_epochs=2, lr=0.01)\n",
    "\n",
    "print(\"学习到的权重：\", weights)\n",
    "weights = weights.numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10888253, 0.00633697, 0.14909117, 0.18238236, 0.04045735,\n",
       "       0.0181999 , 0.00896531, 0.00670692, 0.00279502, 0.02455747,\n",
       "       0.05866915, 0.01003918, 0.03733779, 0.00725143, 0.05651517,\n",
       "       0.01851781, 0.02768733, 0.00434319, 0.01039366, 0.01779089,\n",
       "       0.02455498, 0.01121231, 0.01433938, 0.02713512, 0.00160947,\n",
       "       0.0207767 , 0.02811486, 0.00552378, 0.00607234, 0.00759936,\n",
       "       0.03189143, 0.0098914 , 0.01435831], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998 1998 1998 1998 1998 1998\n",
      "+-----------------------+---------+----------+------------+\n",
      "|       score_type      | pearson | spearman | kendalltau |\n",
      "+-----------------------+---------+----------+------------+\n",
      "|      direct_score     |  0.393  |  0.334   |   0.285    |\n",
      "|     weighted_score    |  0.423  |  0.386   |   0.285    |\n",
      "| weighted_direct_score |  0.406  |  0.343   |   0.253    |\n",
      "|     internalscore     |   0.44  |   0.41   |    0.3     |\n",
      "|       pre_score1      |  0.438  |  0.394   |   0.294    |\n",
      "|       pre_score3      |  0.487  |  0.472   |   0.339    |\n",
      "|       pre_score2      |  0.459  |  0.433   |   0.319    |\n",
      "|       pre_score4      |  0.333  |  0.319   |   0.238    |\n",
      "+-----------------------+---------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyexpat import model\n",
    "from scipy.stats import spearmanr,pearsonr,kendalltau\n",
    "import os\n",
    "import argparse\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def calc_corr(pred_score, score_type,human_score,type_r = 'pearson' ):\n",
    "    r_ls = ['pearson','spearman','kendalltau']\n",
    "    with open(f'predscore_{score_type}.json','w') as f:\n",
    "        json.dump(pred_score,f)\n",
    "    if type_r not in r_ls:\n",
    "        raise ValueError('type_r must be one of {}'.format(r_ls))\n",
    "    elif type_r == 'pearson':\n",
    "        r = pearsonr(pred_score, human_score)[0]\n",
    "    elif type_r == 'kendalltau':\n",
    "        r = kendalltau(pred_score, human_score)[0]\n",
    "    else:\n",
    "        r = spearmanr(pred_score, human_score)[0]\n",
    "    return r\n",
    "\n",
    "def print_correlations(all_score_dict,human_score):\n",
    "    metrics = ['pearson','spearman','kendalltau']   \n",
    "    scores = ['direct_score','weighted_score','weighted_direct_score','internalscore','pre_score1','pre_score3','pre_score2','pre_score4']\n",
    "    table = PrettyTable(['score_type']+metrics)\n",
    "    for score in scores:\n",
    "        add_row = [score] +[round(calc_corr(all_score_dict[score],score_type=score,human_score=human_score,type_r = 'pearson'),3),\n",
    "                            round(calc_corr(all_score_dict[score],score_type='',human_score=human_score,type_r = 'spearman'),3),\n",
    "                            round(calc_corr(all_score_dict[score],score_type='',human_score=human_score,type_r = 'kendalltau'),3)]\n",
    "        table.add_row(add_row)\n",
    "    print(table)\n",
    "\n",
    "if 'tulu' in data_path.lower():\n",
    "    model_name = 'Llama-3___1-Tulu-3-8B'\n",
    "elif 'llama' in data_path.lower():\n",
    "    model_name = 'Meta-Llama-3___1-8B-Instruct'\n",
    "elif 'mistral' in data_path.lower():\n",
    "    model_name = 'Mistral-7B-Instruct-v0___3'\n",
    "elif 'internlm' in data_path.lower():\n",
    "    model_name = 'internlm3-8b-instruct'\n",
    "elif 'qwen' in data_path.lower():\n",
    "    model_name = 'Qwen2___5-7B-Instruct'\n",
    "\n",
    "#data_path = f'/home/laip/InternalScore/results/helpsteer/{model_name}_with_feedback_logits.json'\n",
    "#data_path = f'/home/laip/InternalScore/results/helpsteer/{model_name}_logits.json'\n",
    "\n",
    "#data_path = f'/home/laip/InternalScore/results/flask/{model_name}_with_feedback_logits.json'\n",
    "data_path = f'/home/laip/InternalScore/results/flask/{model_name}_logits.json'\n",
    "#data_path = '/home/laip/InternalScore/results/flask/Llama-2-7b-chat-hf_logits.json'\n",
    "#data_path = '/home/laip/InternalScore/results/flask/Mistral-7B-Instruct-v0___2_logits.json'\n",
    "all_human_score = []\n",
    "\n",
    "\n",
    "all_res = json.load(open(data_path))\n",
    "direct_score_ls = []\n",
    "weighted_score_ls = []\n",
    "weighted_direct_score_ls= []\n",
    "internalscore_ls = []\n",
    "save_ls = []\n",
    "pre_score_ls1 = []\n",
    "pre_score_ls2 = []\n",
    "pre_score_ls3 = []\n",
    "pre_score_ls4 = []\n",
    "ratio = 0.9\n",
    "cos = 0.02\n",
    "score = np.array([[1,2,3,4,5] for i in range(pd.DataFrame(all_res[0]['df']).shape[0])])\n",
    "final_score  = pd.DataFrame(score)\n",
    "\n",
    "\n",
    "for i in range(len(all_res)):\n",
    "    res = all_res[i]\n",
    "    \n",
    "    if res['weighted_socre'] == -1:\n",
    "        continue\n",
    "    all_human_score.append(res['human_score'])\n",
    "    df = pd.DataFrame(res['df']) \n",
    "    score = np.array([1,2,3,4,5])\n",
    "\n",
    "    # weighed_score 加权\n",
    "    distribution1 = df['logits'].apply(lambda x:torch.tensor(x,dtype=torch.float32).softmax(dim=-1))\n",
    "    pre_score1 = ((distribution1.apply(lambda x:(x*torch.tensor([1,2,3,4,5],dtype=torch.float32)).sum()))*weights).sum().item()\n",
    "\n",
    "    # 累积logits 加权\n",
    "    logits = df['logits'].apply(lambda x:torch.tensor(x,dtype=torch.float32))\n",
    "    distribution2 = (logits).apply(lambda x:torch.tensor(x,dtype=torch.float32).argmax(dim=-1))\n",
    "    pre_score = ((torch.tensor([ i+1 for i in distribution2]))*weights).sum().item()\n",
    "\n",
    "    distribution2 = torch.softmax((logits*weights).sum(),dim=-1)\n",
    "    pre_score2 = ((distribution2*torch.tensor([1,2,3,4,5],dtype=torch.float32)).sum()).item()\n",
    "    #print(pre_score2)\n",
    "    #pre_score2 = torch.argmax(distribution2).item()+1\n",
    "\n",
    "    # 累积logits 不加权    \n",
    "    distribution3 = torch.softmax((logits/weights.shape[0]).sum(),dim=-1)\n",
    "    pre_score3 = (distribution3*torch.tensor([1,2,3,4,5],dtype=torch.float32)).sum().item()\n",
    "\n",
    "    # ratio + cosine similarity 筛选\n",
    "   # logits = df[(df['ratio']>ratio)&(df['weights']>cos)]['logits'].apply(lambda x:torch.tensor(x,dtype=torch.float32))\n",
    "    logits = df[(df['ratio']>ratio)]['logits'].apply(lambda x:torch.tensor(x,dtype=torch.float32))\n",
    "    distribution4 = torch.softmax((logits/logits.shape[0]).sum(),dim=-1)\n",
    "    pre_score4 = (distribution4*torch.tensor([1,2,3,4,5],dtype=torch.float32)).sum().item()\n",
    "\n",
    "    prompt = res['prompt']\n",
    "    direct_score_ls.append(res['direct_socre'])\n",
    "    weighted_score_ls.append(res['weighted_socre'])\n",
    "    weighted_direct_score_ls.append(res['weighted_direct_socre'])\n",
    "    internalscore_ls.append(res['internalscore'])\n",
    "    pre_score_ls1.append(pre_score1)\n",
    "    pre_score_ls2.append(pre_score2)\n",
    "    pre_score_ls3.append(pre_score3)\n",
    "    pre_score_ls4.append(pre_score)\n",
    "    \n",
    "    #internalscore_ls.append((df['weighted_score']*weights).sum())\n",
    "#print(df[df['ratio']>r].shape[0])\n",
    "print(len(all_human_score),len(direct_score_ls),len(weighted_score_ls),len(weighted_direct_score_ls),len(internalscore_ls),len(pre_score_ls1))\n",
    "all_score_dict = {'direct_score':direct_score_ls,\n",
    "                  'weighted_score':weighted_score_ls,\n",
    "                  'weighted_direct_score':weighted_direct_score_ls,\n",
    "                  'internalscore':internalscore_ls,\n",
    "                  'pre_score1':pre_score_ls1,\n",
    "                  'pre_score2':pre_score_ls2,\n",
    "                  'pre_score3':pre_score_ls3,\n",
    "                  'pre_score4':pre_score_ls4\n",
    "                  }\n",
    "\n",
    "\n",
    "print_correlations(all_score_dict,all_human_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.064607928902617"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_abs(x,y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return (np.abs(x-y)/len(x)).sum()\n",
    "cal_abs(pre_score_ls2,all_human_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_score_ls \n",
    "all_human_score\n",
    "pre_score_ls2\n",
    "pre_score_ls3\n",
    "data_name1 = 'direct_score'\n",
    "with open(f'{data_name1}.json','w') as f:\n",
    "    json.dump(direct_score_ls,f)\n",
    "data_name2 = 'human_score'\n",
    "with open(f'{data_name2}.json','w') as f:\n",
    "    json.dump(all_human_score,f)\n",
    "data_name3 = 'palmscore_w_tuning'\n",
    "with open(f'{data_name3}.json','w') as f:\n",
    "    json.dump(pre_score_ls3,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt =0\n",
    "for i in range(1,7):\n",
    "    for j in range(1,7):\n",
    "        if i**2==4*j:\n",
    "            cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_matrix(a: list[list[int|float]]) -> list[list[int|float]]:\n",
    "\trow_len,col_len = len(a),len(a[0])\n",
    "\tb = [[0]*row_len]*col_len\n",
    "\tfor i in range(row_len):\n",
    "\t\tfor j in range(col_len):\n",
    "\t\t\tb[j][i] = a[i][j]\n",
    "\t\tprint(b)\n",
    "\treturn b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_matrix(a: list[list[int|float]], new_shape: tuple[int, int]) -> list[list[int|float]]:\n",
    "\t#Write your code here and return a python list after reshaping by using numpy's tolist() method\n",
    "\trow_len,col_len = new_shape[0],new_shape[1]\n",
    "\tall_data = []\n",
    "\tfor i in range(len(a)):\n",
    "\t\tfor j in range(len(a[0])):\n",
    "\t\t\tall_data.append(a[i][j])\n",
    "\treshaped_matrix = [[0]*col_len for _ in range(row_len)]\n",
    "\tfor i in range(row_len):\n",
    "\t\tfor j in range(col_len):\n",
    "\t\t\treshaped_matrix[i][j] = all_data[i*col_len+j]\n",
    "\treturn reshaped_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3132616875182228"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
